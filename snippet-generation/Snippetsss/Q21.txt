/Users/rohitchawla/PycharmProjects/tryingtodosomecrap/Corpus/CACM-2337
a sorting problem and its complexity a technique for proving min max norms of sorting algorithms is given one new algorithm for finding the minimum and maximum elements of a set with fewest comparisons is proved optimal with this technique cacm june 1972 pohl i sorting computational complexity computational combinatorics 529 531 ca720608 jb january 30 1978 415 pm 
****************************
/Users/rohitchawla/PycharmProjects/tryingtodosomecrap/Corpus/CACM-3018
covering edges by cliques with regard to keyword conflicts and intersection graphs kellerman has presented a method for determining keyword conflicts and described a heuristic algorithm which solves a certain combinatorial optimization problem in connection with this method this optimization problem is here shown to be equivalent to the problem of covering the edges of a graph by complete subgraphs with the objective of minimizing the number of complete subgraphs a relationship between this edge clique cover problem and the graph coloring problem is established which allows algorithms for either one of these problems to be constructed from algorithm for the other as consequences of this relationship the keyword conflict problem and the edge clique cover problem are shown to be np complete and if pnp then they do not admit polynomial time approximation algorithms which always produce solutions within a factor less than 2 from the optimum cacm february 1978 kou l stockmeyer l wong c watson t keyword conflicts intersection graphs node clique cover edge clique cover computational complexity np complete problems polynomial time heuristics 412 525 532 ca780205 jb march 28 1978 418 pm 
****************************
/Users/rohitchawla/PycharmProjects/tryingtodosomecrap/Corpus/CACM-3086
on the complexity of computing the measure of uai bi the decision tree complexity of computing the measure of the union of n possibly overlapping intervals is shown to be n log n even if comparisons between linear functions of the interval endpoints are allowed the existence of an n log n lower bound to determine whether any two of n real numbers are within of each other is also demonstrated these problems provide an excellent opportunity for discussing the effects of the computational model on the ease of analysis and on the results produced cacm july 1978 fredman m weide b analysis of algorithms combinatorial problems computational complexity computational models decision tree programs lower bounds 525 526 530 539 ca780702 dh february 8 1979 346 pm 
****************************
/Users/rohitchawla/PycharmProjects/tryingtodosomecrap/Corpus/CACM-2325
numerical mathematics and computer science numerical mathematics is viewed as the analysis of continuous algorithms four of the components of numerical mathematics are discussed these are foundations finite precision number systems computational complexity synthesis and analysis of algorithms analysis of error programs and program libraries cacm july 1972 traub j f numerical mathematics computer science mathematics of computation algorithms continuous algorithms 13 50 51 525 ca720703 jb january 30 1978 317 pm 
****************************
/Users/rohitchawla/PycharmProjects/tryingtodosomecrap/Corpus/CACM-2702
on the complexity of lrk testing the problem of determining whether an arbitrary context free grammar is a member of some easily parsed subclass of grammars such as the lrk grammars is considered the time complexity of this problem is analyzed both when k is considered to be a fixed integer and when k is considered to be a parameter of the test in the first case it is shown that for every k there exists an onk2 algorithm for testing the lrk property where n is the size of the grammar in question on the other hand if both k and the subject grammar are problem parameters then the complexity of the problem depends very strongly on the representation chosen for k more specifically it is shown that this problem is np complete when k is expressed in unary when k is expressed in binary the problem is complete for nondeterministic exponential time these results carry over to many other parameterized classes of grammars such as the llk strong llk slrk lck and strong lck grammars cacm december 1975 hunt h b iii szymanski t g ullman j d computational complexity context free grammars parsing lrk grammars np complete problems 412 523 525 ca751205 jb january 5 1978 428 pm 
****************************
/Users/rohitchawla/PycharmProjects/tryingtodosomecrap/Corpus/CACM-2997
convex hulls of finite sets of poin ts in two and three dimensions the convex hulls of sets of n poin ts in two and three dimensions can be determined with on log n operations the presented algorithms use the divide and conquer technique and recursively apply a merge procedure for two nonin tersecting convex hulls since any convex hull algorithm requires at least on log n operations the time complexity of the proposed algorithms is optimal within a multiplicative constant cacm february 1977 preparata f p hong s j computational complexity convex hull optimal algorithms planar set of poin ts spatial set of poin ts 449 525 532 ca770203 jb december 30 1977 247 am 
****************************
/Users/rohitchawla/PycharmProjects/tryingtodosomecrap/Corpus/CACM-2837
new upper bounds for selection the worst case minimum number of comparisons complexity vin of the i th selection problem is considered a new upper bound for vin improves the bound given by the standard hadian sobel algorithm by a generalization of the kirkpatrick hadian sobel algorithm and extends kirkpatricks method to a much wider range of application this generalization compares favorably with a recent algorithm by hyafil cacm september 1976 yap c k selection problem algorithms comparison problems concrete computational complexity upper bounds worst case analysis 525 531 ca760902 jb january 4 1978 948 am 
****************************
/Users/rohitchawla/PycharmProjects/tryingtodosomecrap/Corpus/CACM-2110
an efficient context free parsing algorithm a parsing algorithm which seems to be the most efficient general context free algorithm known is described it is similar to both knuths lrk algorithm and the familiar top down algorithm it has a time bound proportional to n3 where n is the length of the string being parsed in general it has a n2 bound for unambiguous grammars and it runs in linear time on a large class of grammars which seems to include most practical context free programming language grammars in an empirical comparison it appears to be superior to the top down and bottom up algorithms studied by griffiths and petrick cacm february 1970 earley j syntax analysis parsing context free grammar compilers computational complexity 412 522 523 ca700205 jb february 14 1978 1035 am 
****************************
/Users/rohitchawla/PycharmProjects/tryingtodosomecrap/Corpus/CACM-3110
assembling code for machines with span dependent instructions many modern computers contain instructions whose lengths depend on the distance from a given instance of such an instruction to the operand of that instruction this paper considers the problem of minimizing the lengths of programs for such machines an efficient solution is presented for the case in which the operand of every such span dependent instruction is either a label or an assembly time expression of a certain restricted formf this restriction is relaxed by allowing these operands to be more general assembly time expressions then the problem is shown to be np complete cacm april 1978 szymanski t span dependent instructions variable length addressing code generation assemblers compilers np complete computational complexity 411 412 525 ca780406 dh february 26 1979 349 pm 
****************************
/Users/rohitchawla/PycharmProjects/tryingtodosomecrap/Corpus/CACM-2927
some new upper bounds on the generation of prime numbers given an integer n what is the computational complexity of finding all the primes less than n a modified sieve of eratosthenes using doubly linked lists yields an algorithm of on arithmetic complexity this upper bound is shown to be equivalent to the theoretical lower bound for sieve methods without preprocessing use of preprocessing techniques involving space time and additive multiplicative tradeoffs reduces this upper bound to onlog logn and the bit complexity to on logn log log logn a storage requirement is described using on lognlog logn bits as well cacm september 1977 mairson h g computational complexity sieve prime number generation number theory linked list preprocessing balancing 525 539 ca770907 jb december 27 1977 1255 pm 
****************************
